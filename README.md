# Assessment of Large Language Models (LLMs) and Amazon Mturk workers performance in comparison to experts in tweets' annotation for public perception of vaccines

This repository assesses the performance of LLMs (GPT versions 3.5 and 4, and Mistral) and Amazon Mturk workers in comparison with experts annotators when annotating tweets for public perception on vaccines.

Since Twitter/X data cannot be freely accessible, only certain data is available under the folder 'data', including the tweets id with at least partial agreement among experts.

For visualising the main results of the analysis, including a Shiny application, please do the following steps:

1. Open the R project. 
2. Check that the working directory is "~/gpt_annotation". If not, change it to that path.
3. Open "scripts/main.R"
4. Source the code of the scripts with all data publicly available, indicated by "(public)" 

## Structure of this repository

